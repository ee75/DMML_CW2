{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.svm import SVC\n",
    "from keras.utils import to_categorical\n",
    "import warnings\n",
    "import sklearn.exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main X and Y data\n",
    "x_train = pd.read_csv('Data/x_train_gr_smpl.csv')\n",
    "x_test = pd.read_csv('Data/x_test_gr_smpl.csv')\n",
    "\n",
    "y_train = pd.read_csv('Data/y_train_smpl.csv')\n",
    "y_test = pd.read_csv('Data/y_test_smpl.csv')\n",
    "\n",
    "\n",
    "# One-Vs-Rest Y data\n",
    "# Training data\n",
    "y_train_0 = pd.read_csv('Data/y_train_smpl_0.csv')\n",
    "y_train_1 = pd.read_csv('Data/y_train_smpl_1.csv')\n",
    "y_train_2 = pd.read_csv('Data/y_train_smpl_2.csv')\n",
    "y_train_3 = pd.read_csv('Data/y_train_smpl_3.csv')\n",
    "y_train_4 = pd.read_csv('Data/y_train_smpl_4.csv')\n",
    "y_train_5 = pd.read_csv('Data/y_train_smpl_5.csv')\n",
    "y_train_6 = pd.read_csv('Data/y_train_smpl_6.csv')\n",
    "y_train_7 = pd.read_csv('Data/y_train_smpl_7.csv')\n",
    "y_train_8 = pd.read_csv('Data/y_train_smpl_8.csv')\n",
    "y_train_9 = pd.read_csv('Data/y_train_smpl_9.csv')\n",
    "\n",
    "# Testing Data\n",
    "y_test_0 = pd.read_csv('Data/y_test_smpl_0.csv')\n",
    "y_test_1 = pd.read_csv('Data/y_test_smpl_1.csv')\n",
    "y_test_2 = pd.read_csv('Data/y_test_smpl_2.csv')\n",
    "y_test_3 = pd.read_csv('Data/y_test_smpl_3.csv')\n",
    "y_test_4 = pd.read_csv('Data/y_test_smpl_4.csv')\n",
    "y_test_5 = pd.read_csv('Data/y_test_smpl_5.csv')\n",
    "y_test_6 = pd.read_csv('Data/y_test_smpl_6.csv')\n",
    "y_test_7 = pd.read_csv('Data/y_test_smpl_7.csv')\n",
    "y_test_8 = pd.read_csv('Data/y_test_smpl_8.csv')\n",
    "y_test_9 = pd.read_csv('Data/y_test_smpl_9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Linear Classifier Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_classifier(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    y_train = np.array(y_train).flatten()\n",
    "    y_test = y_test.values.flatten()\n",
    "    \n",
    "    model = SVC()\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    score = model.score(x_test, y_test)\n",
    "    \n",
    "    return print('Score of Linear Classifier:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Neural Network Function, Analyze and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train.reshape(len(x_train), 48, 48)\n",
    "    x_train = x_train/255\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    x_test = x_test.reshape(len(x_test), 48, 48)\n",
    "    x_test = x_test/255\n",
    "\n",
    "    # Neural Network Model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape = [48,48]))\n",
    "    \n",
    "    for i in range(2):\n",
    "        model.add(Dense(units=100, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    opt = SGD(learning_rate=0.01) \n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=5)\n",
    "    y_pred = np.argmax(model.predict(x_test, verbose=0), axis=-1)\n",
    "\n",
    "    print('---------------------------------------------------------------------------------------------------------------')\n",
    "    print('\\n')\n",
    "    print('Results')\n",
    "    # Analyzing the results\n",
    "    # Model Accuracy\n",
    "    print('\\n')\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    print('\\n')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    print('\\n')\n",
    "    \n",
    "    # True Positive\n",
    "    TP = np.diag(cm)\n",
    "    # False Positive\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    # False Negative\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    # True Negative\n",
    "    TN = cm.sum() - (FP+FN+TP)\n",
    "\n",
    "\n",
    "    #True Positive Rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    TPR_mean = np.round(TPR.mean(), 2)\n",
    "    #False Positive Rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    FPR_mean = np.round(FPR.mean(), 2)\n",
    "    #Precision\n",
    "    Precision = TP/(TP+FP)\n",
    "    Precision_mean = np.round(Precision.mean(), 2)\n",
    "    #Recall\n",
    "    Recall = TP/(TP+FN)\n",
    "    Recall_mean = np.round(Recall.mean(), 2)\n",
    "    #F1 Measure\n",
    "    F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    F1_mean = np.round(F1.mean(), 2)\n",
    "    \n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    np.set_printoptions(precision=2)\n",
    "    print('---------------------------------------------------------------------------------------------------------------')\n",
    "    print('\\n')\n",
    "    print('TP rate: ', TPR)\n",
    "    print('Mean TP rate: ', TPR_mean)\n",
    "    print('FP rate: ', FPR)\n",
    "    print('Mean FP rate: ', FPR_mean)\n",
    "    print('Precision: ', Precision)\n",
    "    print('Mean Precision: ', Precision_mean)\n",
    "    print('Recall: ', Recall)\n",
    "    print('Mean Recall: ', Recall_mean)\n",
    "    print('F Measure: ', F1)\n",
    "    print('Mean F Measure: ', F1_mean)\n",
    "    print('ROC Area: ', roc_auc)\n",
    "    print('\\n')\n",
    "    \n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Visualizing the results\n",
    "    # Heatmap\n",
    "    print('---------------------------------------------------------------------------------------------------------------')\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('Visualization of Results')\n",
    "    plt.figure(figsize=(11,7))\n",
    "    sns.heatmap(cm, annot=True, fmt=' .0f', square=True, cmap='BuPu')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Heatmap of Confusion Matrix')\n",
    "    \n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.scatter(Precision, Recall, c='purple')\n",
    "    plt.xlabel('Precsion')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.title('Precision vs Recall Scatter Chart')\n",
    "    plt.show()\n",
    "    print('---------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Convolutional Neural Network, Analyze and Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_neural_network(x_train, y_train, x_test, y_test):    \n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    x_train = x_train.reshape((len(x_train), 48, 48, 1))\n",
    "    x_train = x_train/255\n",
    "\n",
    "    x_test = np.array(x_test)\n",
    "    x_test = x_test.reshape((len(x_test), 48, 48, 1))\n",
    "    x_test = x_test/255\n",
    "\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test_ = y_test.copy()\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    \n",
    "    # Neural Network Model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), input_shape=(48,48,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=48)\n",
    "    \n",
    "    y_pred = np.argmax(model.predict(x_test, verbose=0), axis=-1)\n",
    "    \n",
    "    print('---------------------------------------------------------------------------------------------------------------')\n",
    "    print('\\n')\n",
    "    print('Results')\n",
    "    # Analyzing the results\n",
    "    # Model Accuracy\n",
    "    print('\\n')\n",
    "    scores = model.evaluate(x_test, y_test)\n",
    "    print(f'{model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    print('\\n')\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    y_test = y_test_.copy()\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    print('\\n')\n",
    "    \n",
    "    # True Positive\n",
    "    TP = np.diag(cm)\n",
    "    # False Positive\n",
    "    FP = cm.sum(axis=0) - TP\n",
    "    # False Negative\n",
    "    FN = cm.sum(axis=1) - TP\n",
    "    # True Negative\n",
    "    TN = cm.sum() - (FP+FN+TP)\n",
    "\n",
    "\n",
    "    #True Positive Rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    TPR_mean = np.round(TPR.mean(), 2)\n",
    "    #False Positive Rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    FPR_mean = np.round(FPR.mean(), 2)\n",
    "    #Precision\n",
    "    Precision = TP/(TP+FP)\n",
    "    Precision_mean = np.round(Precision.mean(), 2)\n",
    "    #Recall\n",
    "    Recall = TP/(TP+FN)\n",
    "    Recall_mean = np.round(Recall.mean(), 2)\n",
    "    #F1 Measure\n",
    "    F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "    F1_mean = np.round(F1.mean(), 2)\n",
    "    \n",
    "    roc_auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    np.set_printoptions(precision=2)\n",
    "    print('---------------------------------------------------------------------------------------------------------------')\n",
    "    print('\\n')\n",
    "    print('TP rate: ', TPR)\n",
    "    print('Mean TP rate: ', TPR_mean)\n",
    "    print('FP rate: ', FPR)\n",
    "    print('Mean FP rate: ', FPR_mean)\n",
    "    print('Precision: ', Precision)\n",
    "    print('Mean Precision: ', Precision_mean)\n",
    "    print('Recall: ', Recall)\n",
    "    print('Mean Recall: ', Recall_mean)\n",
    "    print('F Measure: ', F1)\n",
    "    print('Mean F Measure: ', F1_mean)\n",
    "    print('ROC Area: ', roc_auc)\n",
    "    print('\\n')\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Visualizing the results\n",
    "    # Heatmap\n",
    "    print('---------------------------------------------------------------------------------------------------------------')\n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    print('Visualization of Results')\n",
    "    plt.figure(figsize=(11,7))\n",
    "    sns.heatmap(cm, annot=True, fmt=' .0f', square=True, cmap='Set1')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Heatmap of Confusion Matrix')\n",
    "    \n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.scatter(Precision, Recall, c='r')\n",
    "    plt.xlabel('Precsion')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.title('Precision vs Recall Scatter Chart')\n",
    "    plt.show()\n",
    "    print('---------------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-vs-Rest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_0 and Y_test_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_0, x_test, y_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_0, x_test, y_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_1, x_test, y_test_1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_1 and Y_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_1, x_test, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_1, x_test, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_1, x_test, y_test_1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_2 and Y_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_2, x_test, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_2, x_test, y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_2, x_test, y_test_2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_3 and Y_test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_3, x_test, y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_3, x_test, y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_3, x_test, y_test_3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_4 and Y_test_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_4, x_test, y_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_4, x_test, y_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_4, x_test, y_test_4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_5 and Y_test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_5, x_test, y_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_5, x_test, y_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_5, x_test, y_test_5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_6 and Y_test_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_6, x_test, y_test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_6, x_test, y_test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_6, x_test, y_test_6 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_7 and 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_7, x_test, y_test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_7, x_test, y_test_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_7, x_test, y_test_7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_8 and Y_test_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_8, x_test, y_test_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_8, x_test, y_test_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_8, x_test, y_test_8 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y_train_9 and Y_test_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_classifier(x_train, y_train_9, x_test, y_test_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network(x_train, y_train_9, x_test, y_test_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_neural_network(x_train, y_train_9, x_test, y_test_9 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
